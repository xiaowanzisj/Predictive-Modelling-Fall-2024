{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy.linalg import toeplitz\n",
    "from statsmodels.tsa.stattools import acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/xiaowanzisj/Data-Science-1/refs/heads/main/dataset_lm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 422 entries, 0 to 421\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Dependent Var        422 non-null    float64\n",
      " 1   Explanatory Var #1   422 non-null    float64\n",
      " 2   Explanatory Var #2   422 non-null    float64\n",
      " 3   Explanatory Var #3   422 non-null    int64  \n",
      " 4   Explanatory Var #4   422 non-null    float64\n",
      " 5   Explanatory Var #5   422 non-null    float64\n",
      " 6   Explanatory Var #6   422 non-null    float64\n",
      " 7   Explanatory Var #7   422 non-null    float64\n",
      " 8   Explanatory Var #8   422 non-null    int64  \n",
      " 9   Explanatory Var #9   422 non-null    float64\n",
      " 10  Explanatory Var #10  422 non-null    float64\n",
      " 11  Explanatory Var #11  422 non-null    float64\n",
      " 12  Explanatory Var #12  422 non-null    float64\n",
      " 13  Explanatory Var #13  422 non-null    int64  \n",
      " 14  Explanatory Var #14  422 non-null    float64\n",
      " 15  Explanatory Var #15  422 non-null    float64\n",
      "dtypes: float64(13), int64(3)\n",
      "memory usage: 52.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dependent Var</th>\n",
       "      <th>Explanatory Var #1</th>\n",
       "      <th>Explanatory Var #2</th>\n",
       "      <th>Explanatory Var #3</th>\n",
       "      <th>Explanatory Var #4</th>\n",
       "      <th>Explanatory Var #5</th>\n",
       "      <th>Explanatory Var #6</th>\n",
       "      <th>Explanatory Var #7</th>\n",
       "      <th>Explanatory Var #8</th>\n",
       "      <th>Explanatory Var #9</th>\n",
       "      <th>Explanatory Var #10</th>\n",
       "      <th>Explanatory Var #11</th>\n",
       "      <th>Explanatory Var #12</th>\n",
       "      <th>Explanatory Var #13</th>\n",
       "      <th>Explanatory Var #14</th>\n",
       "      <th>Explanatory Var #15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.293458</td>\n",
       "      <td>13.698667</td>\n",
       "      <td>50.639873</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.568035</td>\n",
       "      <td>45.121911</td>\n",
       "      <td>11.412501</td>\n",
       "      <td>56.410757</td>\n",
       "      <td>2</td>\n",
       "      <td>-12.281132</td>\n",
       "      <td>38.996909</td>\n",
       "      <td>-3.010548</td>\n",
       "      <td>49.195073</td>\n",
       "      <td>0</td>\n",
       "      <td>-21.153143</td>\n",
       "      <td>46.919314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.473431</td>\n",
       "      <td>2.714725</td>\n",
       "      <td>65.845845</td>\n",
       "      <td>1</td>\n",
       "      <td>-25.105932</td>\n",
       "      <td>47.190213</td>\n",
       "      <td>10.080280</td>\n",
       "      <td>65.383107</td>\n",
       "      <td>3</td>\n",
       "      <td>-36.763585</td>\n",
       "      <td>51.654939</td>\n",
       "      <td>4.991111</td>\n",
       "      <td>45.591729</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.474403</td>\n",
       "      <td>53.383508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94.195330</td>\n",
       "      <td>11.618072</td>\n",
       "      <td>65.072497</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.897464</td>\n",
       "      <td>52.163036</td>\n",
       "      <td>11.057301</td>\n",
       "      <td>82.812717</td>\n",
       "      <td>0</td>\n",
       "      <td>-15.733547</td>\n",
       "      <td>48.913837</td>\n",
       "      <td>-2.457696</td>\n",
       "      <td>56.608806</td>\n",
       "      <td>0</td>\n",
       "      <td>-27.903299</td>\n",
       "      <td>48.515026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.074583</td>\n",
       "      <td>0.818623</td>\n",
       "      <td>45.408996</td>\n",
       "      <td>1</td>\n",
       "      <td>-18.316132</td>\n",
       "      <td>54.356714</td>\n",
       "      <td>5.029029</td>\n",
       "      <td>48.812471</td>\n",
       "      <td>1</td>\n",
       "      <td>-12.825591</td>\n",
       "      <td>45.851732</td>\n",
       "      <td>14.974177</td>\n",
       "      <td>47.362594</td>\n",
       "      <td>1</td>\n",
       "      <td>-10.064411</td>\n",
       "      <td>55.266254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86.035569</td>\n",
       "      <td>9.077544</td>\n",
       "      <td>73.548021</td>\n",
       "      <td>0</td>\n",
       "      <td>-19.204165</td>\n",
       "      <td>47.186807</td>\n",
       "      <td>12.128134</td>\n",
       "      <td>62.520911</td>\n",
       "      <td>2</td>\n",
       "      <td>-13.804860</td>\n",
       "      <td>47.765904</td>\n",
       "      <td>9.593982</td>\n",
       "      <td>53.700562</td>\n",
       "      <td>0</td>\n",
       "      <td>-17.546302</td>\n",
       "      <td>48.150543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>61.300432</td>\n",
       "      <td>0.338441</td>\n",
       "      <td>70.430598</td>\n",
       "      <td>0</td>\n",
       "      <td>-21.525979</td>\n",
       "      <td>50.741115</td>\n",
       "      <td>-8.050843</td>\n",
       "      <td>39.075397</td>\n",
       "      <td>3</td>\n",
       "      <td>-29.197173</td>\n",
       "      <td>57.473862</td>\n",
       "      <td>15.505202</td>\n",
       "      <td>73.280605</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.602482</td>\n",
       "      <td>56.317474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>26.309237</td>\n",
       "      <td>-1.729712</td>\n",
       "      <td>47.087996</td>\n",
       "      <td>1</td>\n",
       "      <td>-19.034807</td>\n",
       "      <td>55.242929</td>\n",
       "      <td>28.001769</td>\n",
       "      <td>76.429649</td>\n",
       "      <td>0</td>\n",
       "      <td>-21.941401</td>\n",
       "      <td>54.641620</td>\n",
       "      <td>14.295688</td>\n",
       "      <td>49.816798</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.910494</td>\n",
       "      <td>52.827988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>58.350627</td>\n",
       "      <td>18.322301</td>\n",
       "      <td>53.267835</td>\n",
       "      <td>0</td>\n",
       "      <td>-26.186201</td>\n",
       "      <td>36.702958</td>\n",
       "      <td>14.530116</td>\n",
       "      <td>51.275150</td>\n",
       "      <td>2</td>\n",
       "      <td>-20.699670</td>\n",
       "      <td>46.443687</td>\n",
       "      <td>5.708762</td>\n",
       "      <td>52.751016</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.202345</td>\n",
       "      <td>52.467289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>31.954003</td>\n",
       "      <td>0.436357</td>\n",
       "      <td>61.844132</td>\n",
       "      <td>0</td>\n",
       "      <td>-25.881961</td>\n",
       "      <td>57.106851</td>\n",
       "      <td>21.786066</td>\n",
       "      <td>68.928442</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.166461</td>\n",
       "      <td>59.194840</td>\n",
       "      <td>8.365762</td>\n",
       "      <td>64.291056</td>\n",
       "      <td>1</td>\n",
       "      <td>-21.330017</td>\n",
       "      <td>50.237673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>50.590958</td>\n",
       "      <td>-3.107425</td>\n",
       "      <td>64.590632</td>\n",
       "      <td>1</td>\n",
       "      <td>-20.303215</td>\n",
       "      <td>56.374124</td>\n",
       "      <td>4.604237</td>\n",
       "      <td>49.501005</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.792745</td>\n",
       "      <td>45.594612</td>\n",
       "      <td>16.414449</td>\n",
       "      <td>66.957547</td>\n",
       "      <td>0</td>\n",
       "      <td>-15.771155</td>\n",
       "      <td>43.603802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>422 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dependent Var  Explanatory Var #1  Explanatory Var #2  \\\n",
       "0        56.293458           13.698667           50.639873   \n",
       "1        58.473431            2.714725           65.845845   \n",
       "2        94.195330           11.618072           65.072497   \n",
       "3        29.074583            0.818623           45.408996   \n",
       "4        86.035569            9.077544           73.548021   \n",
       "..             ...                 ...                 ...   \n",
       "417      61.300432            0.338441           70.430598   \n",
       "418      26.309237           -1.729712           47.087996   \n",
       "419      58.350627           18.322301           53.267835   \n",
       "420      31.954003            0.436357           61.844132   \n",
       "421      50.590958           -3.107425           64.590632   \n",
       "\n",
       "     Explanatory Var #3  Explanatory Var #4  Explanatory Var #5  \\\n",
       "0                     0          -18.568035           45.121911   \n",
       "1                     1          -25.105932           47.190213   \n",
       "2                     0           -7.897464           52.163036   \n",
       "3                     1          -18.316132           54.356714   \n",
       "4                     0          -19.204165           47.186807   \n",
       "..                  ...                 ...                 ...   \n",
       "417                   0          -21.525979           50.741115   \n",
       "418                   1          -19.034807           55.242929   \n",
       "419                   0          -26.186201           36.702958   \n",
       "420                   0          -25.881961           57.106851   \n",
       "421                   1          -20.303215           56.374124   \n",
       "\n",
       "     Explanatory Var #6  Explanatory Var #7  Explanatory Var #8  \\\n",
       "0             11.412501           56.410757                   2   \n",
       "1             10.080280           65.383107                   3   \n",
       "2             11.057301           82.812717                   0   \n",
       "3              5.029029           48.812471                   1   \n",
       "4             12.128134           62.520911                   2   \n",
       "..                  ...                 ...                 ...   \n",
       "417           -8.050843           39.075397                   3   \n",
       "418           28.001769           76.429649                   0   \n",
       "419           14.530116           51.275150                   2   \n",
       "420           21.786066           68.928442                   0   \n",
       "421            4.604237           49.501005                   0   \n",
       "\n",
       "     Explanatory Var #9  Explanatory Var #10  Explanatory Var #11  \\\n",
       "0            -12.281132            38.996909            -3.010548   \n",
       "1            -36.763585            51.654939             4.991111   \n",
       "2            -15.733547            48.913837            -2.457696   \n",
       "3            -12.825591            45.851732            14.974177   \n",
       "4            -13.804860            47.765904             9.593982   \n",
       "..                  ...                  ...                  ...   \n",
       "417          -29.197173            57.473862            15.505202   \n",
       "418          -21.941401            54.641620            14.295688   \n",
       "419          -20.699670            46.443687             5.708762   \n",
       "420          -23.166461            59.194840             8.365762   \n",
       "421          -18.792745            45.594612            16.414449   \n",
       "\n",
       "     Explanatory Var #12  Explanatory Var #13  Explanatory Var #14  \\\n",
       "0              49.195073                    0           -21.153143   \n",
       "1              45.591729                    0            -6.474403   \n",
       "2              56.608806                    0           -27.903299   \n",
       "3              47.362594                    1           -10.064411   \n",
       "4              53.700562                    0           -17.546302   \n",
       "..                   ...                  ...                  ...   \n",
       "417            73.280605                    1            -3.602482   \n",
       "418            49.816798                    1           -13.910494   \n",
       "419            52.751016                    1            -6.202345   \n",
       "420            64.291056                    1           -21.330017   \n",
       "421            66.957547                    0           -15.771155   \n",
       "\n",
       "     Explanatory Var #15  \n",
       "0              46.919314  \n",
       "1              53.383508  \n",
       "2              48.515026  \n",
       "3              55.266254  \n",
       "4              48.150543  \n",
       "..                   ...  \n",
       "417            56.317474  \n",
       "418            52.827988  \n",
       "419            52.467289  \n",
       "420            50.237673  \n",
       "421            43.603802  \n",
       "\n",
       "[422 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dependent Var          0\n",
       "Explanatory Var #1     0\n",
       "Explanatory Var #2     0\n",
       "Explanatory Var #3     0\n",
       "Explanatory Var #4     0\n",
       "Explanatory Var #5     0\n",
       "Explanatory Var #6     0\n",
       "Explanatory Var #7     0\n",
       "Explanatory Var #8     0\n",
       "Explanatory Var #9     0\n",
       "Explanatory Var #10    0\n",
       "Explanatory Var #11    0\n",
       "Explanatory Var #12    0\n",
       "Explanatory Var #13    0\n",
       "Explanatory Var #14    0\n",
       "Explanatory Var #15    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A (25%)\n",
    "1.\tDownload the “dataset_lm.csv” file from Canvas and upload it to Jupyter Notebook. \n",
    "2.\tRun the OLS model by using the dependent and explanatory variables in the dataset. \n",
    "3.\tShow your summary table in Python and interpret your results in the summary report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Dependent Var']\n",
    "x = df.drop('Dependent Var', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Dependent Var</td>  <th>  R-squared:         </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>1.682e+30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 18 Oct 2024</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:33:35</td>     <th>  Log-Likelihood:    </th>  <td>  12021.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   422</td>      <th>  AIC:               </th> <td>-2.401e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   406</td>      <th>  BIC:               </th> <td>-2.395e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td>   32.0000</td> <td> 9.19e-14</td> <td> 3.48e+14</td> <td> 0.000</td> <td>   32.000</td> <td>   32.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #1</th>  <td>    1.3000</td> <td> 7.42e-16</td> <td> 1.75e+15</td> <td> 0.000</td> <td>    1.300</td> <td>    1.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #2</th>  <td>    1.7000</td> <td> 5.39e-16</td> <td> 3.15e+15</td> <td> 0.000</td> <td>    1.700</td> <td>    1.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #3</th>  <td>    6.2000</td> <td> 1.03e-14</td> <td> 5.99e+14</td> <td> 0.000</td> <td>    6.200</td> <td>    6.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #4</th>  <td>    2.1000</td> <td> 6.37e-16</td> <td>  3.3e+15</td> <td> 0.000</td> <td>    2.100</td> <td>    2.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #5</th>  <td>   -0.9000</td> <td> 7.47e-16</td> <td>-1.21e+15</td> <td> 0.000</td> <td>   -0.900</td> <td>   -0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #6</th>  <td> 2.276e-15</td> <td> 4.51e-16</td> <td>    5.051</td> <td> 0.000</td> <td> 1.39e-15</td> <td> 3.16e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #7</th>  <td> 3.018e-16</td> <td> 3.48e-16</td> <td>    0.867</td> <td> 0.386</td> <td>-3.82e-16</td> <td> 9.86e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #8</th>  <td>-6.217e-15</td> <td> 4.73e-15</td> <td>   -1.314</td> <td> 0.189</td> <td>-1.55e-14</td> <td> 3.08e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #9</th>  <td>-9.923e-16</td> <td> 6.05e-16</td> <td>   -1.641</td> <td> 0.102</td> <td>-2.18e-15</td> <td> 1.97e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #10</th> <td>-3.691e-15</td> <td> 7.54e-16</td> <td>   -4.897</td> <td> 0.000</td> <td>-5.17e-15</td> <td>-2.21e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #11</th> <td> 1.277e-15</td> <td> 7.29e-16</td> <td>    1.751</td> <td> 0.081</td> <td>-1.56e-16</td> <td> 2.71e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #12</th> <td>-9.437e-16</td> <td> 5.45e-16</td> <td>   -1.730</td> <td> 0.084</td> <td>-2.02e-15</td> <td> 1.28e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #13</th> <td>-3.553e-15</td> <td> 1.04e-14</td> <td>   -0.340</td> <td> 0.734</td> <td>-2.41e-14</td> <td>  1.7e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #14</th> <td>-1.596e-15</td> <td> 6.41e-16</td> <td>   -2.488</td> <td> 0.013</td> <td>-2.86e-15</td> <td>-3.35e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #15</th> <td>-3.358e-15</td> <td> 7.64e-16</td> <td>   -4.397</td> <td> 0.000</td> <td>-4.86e-15</td> <td>-1.86e-15</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.439</td> <th>  Durbin-Watson:     </th> <td>   0.781</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.295</td> <th>  Jarque-Bera (JB):  </th> <td>   2.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.044</td> <th>  Prob(JB):          </th> <td>   0.358</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.670</td> <th>  Cond. No.          </th> <td>2.55e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.55e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}       &  Dependent Var   & \\textbf{  R-squared:         } &     1.000   \\\\\n",
       "\\textbf{Model:}               &       OLS        & \\textbf{  Adj. R-squared:    } &     1.000   \\\\\n",
       "\\textbf{Method:}              &  Least Squares   & \\textbf{  F-statistic:       } & 1.682e+30   \\\\\n",
       "\\textbf{Date:}                & Fri, 18 Oct 2024 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}                &     20:33:35     & \\textbf{  Log-Likelihood:    } &    12021.   \\\\\n",
       "\\textbf{No. Observations:}    &         422      & \\textbf{  AIC:               } & -2.401e+04  \\\\\n",
       "\\textbf{Df Residuals:}        &         406      & \\textbf{  BIC:               } & -2.395e+04  \\\\\n",
       "\\textbf{Df Model:}            &          15      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}     &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                              & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}                &      32.0000  &     9.19e-14     &  3.48e+14  &         0.000        &       32.000    &       32.000     \\\\\n",
       "\\textbf{Explanatory Var \\#1}  &       1.3000  &     7.42e-16     &  1.75e+15  &         0.000        &        1.300    &        1.300     \\\\\n",
       "\\textbf{Explanatory Var \\#2}  &       1.7000  &     5.39e-16     &  3.15e+15  &         0.000        &        1.700    &        1.700     \\\\\n",
       "\\textbf{Explanatory Var \\#3}  &       6.2000  &     1.03e-14     &  5.99e+14  &         0.000        &        6.200    &        6.200     \\\\\n",
       "\\textbf{Explanatory Var \\#4}  &       2.1000  &     6.37e-16     &   3.3e+15  &         0.000        &        2.100    &        2.100     \\\\\n",
       "\\textbf{Explanatory Var \\#5}  &      -0.9000  &     7.47e-16     & -1.21e+15  &         0.000        &       -0.900    &       -0.900     \\\\\n",
       "\\textbf{Explanatory Var \\#6}  &    2.276e-15  &     4.51e-16     &     5.051  &         0.000        &     1.39e-15    &     3.16e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#7}  &    3.018e-16  &     3.48e-16     &     0.867  &         0.386        &    -3.82e-16    &     9.86e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#8}  &   -6.217e-15  &     4.73e-15     &    -1.314  &         0.189        &    -1.55e-14    &     3.08e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#9}  &   -9.923e-16  &     6.05e-16     &    -1.641  &         0.102        &    -2.18e-15    &     1.97e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#10} &   -3.691e-15  &     7.54e-16     &    -4.897  &         0.000        &    -5.17e-15    &    -2.21e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#11} &    1.277e-15  &     7.29e-16     &     1.751  &         0.081        &    -1.56e-16    &     2.71e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#12} &   -9.437e-16  &     5.45e-16     &    -1.730  &         0.084        &    -2.02e-15    &     1.28e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#13} &   -3.553e-15  &     1.04e-14     &    -0.340  &         0.734        &    -2.41e-14    &      1.7e-14     \\\\\n",
       "\\textbf{Explanatory Var \\#14} &   -1.596e-15  &     6.41e-16     &    -2.488  &         0.013        &    -2.86e-15    &    -3.35e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#15} &   -3.358e-15  &     7.64e-16     &    -4.397  &         0.000        &    -4.86e-15    &    -1.86e-15     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  2.439 & \\textbf{  Durbin-Watson:     } &    0.781  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.295 & \\textbf{  Jarque-Bera (JB):  } &    2.053  \\\\\n",
       "\\textbf{Skew:}          &  0.044 & \\textbf{  Prob(JB):          } &    0.358  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.670 & \\textbf{  Cond. No.          } & 2.55e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.55e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:          Dependent Var   R-squared:                       1.000\n",
       "Model:                            OLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 1.682e+30\n",
       "Date:                Fri, 18 Oct 2024   Prob (F-statistic):               0.00\n",
       "Time:                        20:33:35   Log-Likelihood:                 12021.\n",
       "No. Observations:                 422   AIC:                        -2.401e+04\n",
       "Df Residuals:                     406   BIC:                        -2.395e+04\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "const                  32.0000   9.19e-14   3.48e+14      0.000      32.000      32.000\n",
       "Explanatory Var #1      1.3000   7.42e-16   1.75e+15      0.000       1.300       1.300\n",
       "Explanatory Var #2      1.7000   5.39e-16   3.15e+15      0.000       1.700       1.700\n",
       "Explanatory Var #3      6.2000   1.03e-14   5.99e+14      0.000       6.200       6.200\n",
       "Explanatory Var #4      2.1000   6.37e-16    3.3e+15      0.000       2.100       2.100\n",
       "Explanatory Var #5     -0.9000   7.47e-16  -1.21e+15      0.000      -0.900      -0.900\n",
       "Explanatory Var #6   2.276e-15   4.51e-16      5.051      0.000    1.39e-15    3.16e-15\n",
       "Explanatory Var #7   3.018e-16   3.48e-16      0.867      0.386   -3.82e-16    9.86e-16\n",
       "Explanatory Var #8  -6.217e-15   4.73e-15     -1.314      0.189   -1.55e-14    3.08e-15\n",
       "Explanatory Var #9  -9.923e-16   6.05e-16     -1.641      0.102   -2.18e-15    1.97e-16\n",
       "Explanatory Var #10 -3.691e-15   7.54e-16     -4.897      0.000   -5.17e-15   -2.21e-15\n",
       "Explanatory Var #11  1.277e-15   7.29e-16      1.751      0.081   -1.56e-16    2.71e-15\n",
       "Explanatory Var #12 -9.437e-16   5.45e-16     -1.730      0.084   -2.02e-15    1.28e-16\n",
       "Explanatory Var #13 -3.553e-15   1.04e-14     -0.340      0.734   -2.41e-14     1.7e-14\n",
       "Explanatory Var #14 -1.596e-15   6.41e-16     -2.488      0.013   -2.86e-15   -3.35e-16\n",
       "Explanatory Var #15 -3.358e-15   7.64e-16     -4.397      0.000   -4.86e-15   -1.86e-15\n",
       "==============================================================================\n",
       "Omnibus:                        2.439   Durbin-Watson:                   0.781\n",
       "Prob(Omnibus):                  0.295   Jarque-Bera (JB):                2.053\n",
       "Skew:                           0.044   Prob(JB):                        0.358\n",
       "Kurtosis:                       2.670   Cond. No.                     2.55e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.55e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_updated = sm.add_constant(x)\n",
    "model_updated = sm.OLS(y,x_updated).fit()\n",
    "model_updated.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ y = 32.0000 + 1.3000 \\cdot X_1 + 1.7000 \\cdot X_2 + 6.2000 \\cdot X_3 + \\dots + (-8.4316 \\cdot 10^{-16}) \\cdot X_{15} + \\epsilon $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(6.591964783129596e-14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1\n",
    "residuals = model_updated.resid\n",
    "std_deviation = residuals.std()\n",
    "std_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.04566151, -0.02558894, -0.0018177 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acf_residuals = acf(residuals, nlags = 3)\n",
    "acf_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>GLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Dependent Var</td>  <th>  R-squared:         </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>GLS</td>       <th>  Adj. R-squared:    </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>5.089e+29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 18 Oct 2024</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:33:35</td>     <th>  Log-Likelihood:    </th>  <td>  11769.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   422</td>      <th>  AIC:               </th> <td>-2.351e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   406</td>      <th>  BIC:               </th> <td>-2.344e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td>   32.0000</td> <td> 1.67e-13</td> <td> 1.91e+14</td> <td> 0.000</td> <td>   32.000</td> <td>   32.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #1</th>  <td>    1.3000</td> <td> 1.35e-15</td> <td> 9.64e+14</td> <td> 0.000</td> <td>    1.300</td> <td>    1.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #2</th>  <td>    1.7000</td> <td> 9.81e-16</td> <td> 1.73e+15</td> <td> 0.000</td> <td>    1.700</td> <td>    1.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #3</th>  <td>    6.2000</td> <td> 1.88e-14</td> <td>  3.3e+14</td> <td> 0.000</td> <td>    6.200</td> <td>    6.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #4</th>  <td>    2.1000</td> <td> 1.16e-15</td> <td> 1.81e+15</td> <td> 0.000</td> <td>    2.100</td> <td>    2.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #5</th>  <td>   -0.9000</td> <td> 1.36e-15</td> <td>-6.61e+14</td> <td> 0.000</td> <td>   -0.900</td> <td>   -0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #6</th>  <td> 3.608e-16</td> <td> 8.19e-16</td> <td>    0.441</td> <td> 0.660</td> <td>-1.25e-15</td> <td> 1.97e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #7</th>  <td>-1.023e-15</td> <td> 6.33e-16</td> <td>   -1.617</td> <td> 0.107</td> <td>-2.27e-15</td> <td> 2.21e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #8</th>  <td> 1.443e-15</td> <td>  8.6e-15</td> <td>    0.168</td> <td> 0.867</td> <td>-1.55e-14</td> <td> 1.84e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #9</th>  <td>-2.776e-16</td> <td>  1.1e-15</td> <td>   -0.253</td> <td> 0.801</td> <td>-2.44e-15</td> <td> 1.88e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #10</th> <td>  1.11e-16</td> <td> 1.37e-15</td> <td>    0.081</td> <td> 0.935</td> <td>-2.57e-15</td> <td>  2.8e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #11</th> <td>-6.106e-16</td> <td> 1.32e-15</td> <td>   -0.461</td> <td> 0.645</td> <td>-3.21e-15</td> <td> 1.99e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #12</th> <td>-3.442e-15</td> <td> 9.89e-16</td> <td>   -3.478</td> <td> 0.001</td> <td>-5.39e-15</td> <td> -1.5e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #13</th> <td>-7.105e-15</td> <td> 1.89e-14</td> <td>   -0.376</td> <td> 0.707</td> <td>-4.43e-14</td> <td> 3.01e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #14</th> <td>-5.551e-17</td> <td> 1.17e-15</td> <td>   -0.048</td> <td> 0.962</td> <td>-2.35e-15</td> <td> 2.24e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #15</th> <td>-1.082e-15</td> <td> 1.38e-15</td> <td>   -0.783</td> <td> 0.434</td> <td> -3.8e-15</td> <td> 1.63e-15</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>15.230</td> <th>  Durbin-Watson:     </th> <td>   0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>   7.348</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.046</td> <th>  Prob(JB):          </th> <td>  0.0254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.360</td> <th>  Cond. No.          </th> <td>2.44e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.44e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}       &  Dependent Var   & \\textbf{  R-squared:         } &     1.000   \\\\\n",
       "\\textbf{Model:}               &       GLS        & \\textbf{  Adj. R-squared:    } &     1.000   \\\\\n",
       "\\textbf{Method:}              &  Least Squares   & \\textbf{  F-statistic:       } & 5.089e+29   \\\\\n",
       "\\textbf{Date:}                & Fri, 18 Oct 2024 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}                &     20:33:35     & \\textbf{  Log-Likelihood:    } &    11769.   \\\\\n",
       "\\textbf{No. Observations:}    &         422      & \\textbf{  AIC:               } & -2.351e+04  \\\\\n",
       "\\textbf{Df Residuals:}        &         406      & \\textbf{  BIC:               } & -2.344e+04  \\\\\n",
       "\\textbf{Df Model:}            &          15      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}     &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                              & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}                &      32.0000  &     1.67e-13     &  1.91e+14  &         0.000        &       32.000    &       32.000     \\\\\n",
       "\\textbf{Explanatory Var \\#1}  &       1.3000  &     1.35e-15     &  9.64e+14  &         0.000        &        1.300    &        1.300     \\\\\n",
       "\\textbf{Explanatory Var \\#2}  &       1.7000  &     9.81e-16     &  1.73e+15  &         0.000        &        1.700    &        1.700     \\\\\n",
       "\\textbf{Explanatory Var \\#3}  &       6.2000  &     1.88e-14     &   3.3e+14  &         0.000        &        6.200    &        6.200     \\\\\n",
       "\\textbf{Explanatory Var \\#4}  &       2.1000  &     1.16e-15     &  1.81e+15  &         0.000        &        2.100    &        2.100     \\\\\n",
       "\\textbf{Explanatory Var \\#5}  &      -0.9000  &     1.36e-15     & -6.61e+14  &         0.000        &       -0.900    &       -0.900     \\\\\n",
       "\\textbf{Explanatory Var \\#6}  &    3.608e-16  &     8.19e-16     &     0.441  &         0.660        &    -1.25e-15    &     1.97e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#7}  &   -1.023e-15  &     6.33e-16     &    -1.617  &         0.107        &    -2.27e-15    &     2.21e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#8}  &    1.443e-15  &      8.6e-15     &     0.168  &         0.867        &    -1.55e-14    &     1.84e-14     \\\\\n",
       "\\textbf{Explanatory Var \\#9}  &   -2.776e-16  &      1.1e-15     &    -0.253  &         0.801        &    -2.44e-15    &     1.88e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#10} &     1.11e-16  &     1.37e-15     &     0.081  &         0.935        &    -2.57e-15    &      2.8e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#11} &   -6.106e-16  &     1.32e-15     &    -0.461  &         0.645        &    -3.21e-15    &     1.99e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#12} &   -3.442e-15  &     9.89e-16     &    -3.478  &         0.001        &    -5.39e-15    &     -1.5e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#13} &   -7.105e-15  &     1.89e-14     &    -0.376  &         0.707        &    -4.43e-14    &     3.01e-14     \\\\\n",
       "\\textbf{Explanatory Var \\#14} &   -5.551e-17  &     1.17e-15     &    -0.048  &         0.962        &    -2.35e-15    &     2.24e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#15} &   -1.082e-15  &     1.38e-15     &    -0.783  &         0.434        &     -3.8e-15    &     1.63e-15     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 15.230 & \\textbf{  Durbin-Watson:     } &    0.116  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &    7.348  \\\\\n",
       "\\textbf{Skew:}          &  0.046 & \\textbf{  Prob(JB):          } &   0.0254  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.360 & \\textbf{  Cond. No.          } & 2.44e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{GLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.44e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            GLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:          Dependent Var   R-squared:                       1.000\n",
       "Model:                            GLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 5.089e+29\n",
       "Date:                Fri, 18 Oct 2024   Prob (F-statistic):               0.00\n",
       "Time:                        20:33:35   Log-Likelihood:                 11769.\n",
       "No. Observations:                 422   AIC:                        -2.351e+04\n",
       "Df Residuals:                     406   BIC:                        -2.344e+04\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "const                  32.0000   1.67e-13   1.91e+14      0.000      32.000      32.000\n",
       "Explanatory Var #1      1.3000   1.35e-15   9.64e+14      0.000       1.300       1.300\n",
       "Explanatory Var #2      1.7000   9.81e-16   1.73e+15      0.000       1.700       1.700\n",
       "Explanatory Var #3      6.2000   1.88e-14    3.3e+14      0.000       6.200       6.200\n",
       "Explanatory Var #4      2.1000   1.16e-15   1.81e+15      0.000       2.100       2.100\n",
       "Explanatory Var #5     -0.9000   1.36e-15  -6.61e+14      0.000      -0.900      -0.900\n",
       "Explanatory Var #6   3.608e-16   8.19e-16      0.441      0.660   -1.25e-15    1.97e-15\n",
       "Explanatory Var #7  -1.023e-15   6.33e-16     -1.617      0.107   -2.27e-15    2.21e-16\n",
       "Explanatory Var #8   1.443e-15    8.6e-15      0.168      0.867   -1.55e-14    1.84e-14\n",
       "Explanatory Var #9  -2.776e-16    1.1e-15     -0.253      0.801   -2.44e-15    1.88e-15\n",
       "Explanatory Var #10   1.11e-16   1.37e-15      0.081      0.935   -2.57e-15     2.8e-15\n",
       "Explanatory Var #11 -6.106e-16   1.32e-15     -0.461      0.645   -3.21e-15    1.99e-15\n",
       "Explanatory Var #12 -3.442e-15   9.89e-16     -3.478      0.001   -5.39e-15    -1.5e-15\n",
       "Explanatory Var #13 -7.105e-15   1.89e-14     -0.376      0.707   -4.43e-14    3.01e-14\n",
       "Explanatory Var #14 -5.551e-17   1.17e-15     -0.048      0.962   -2.35e-15    2.24e-15\n",
       "Explanatory Var #15 -1.082e-15   1.38e-15     -0.783      0.434    -3.8e-15    1.63e-15\n",
       "==============================================================================\n",
       "Omnibus:                       15.230   Durbin-Watson:                   0.116\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):                7.348\n",
       "Skew:                           0.046   Prob(JB):                       0.0254\n",
       "Kurtosis:                       2.360   Cond. No.                     2.44e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.44e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2\n",
    "rho = acf_residuals[1]\n",
    "n = len(y)\n",
    "cov_matrix = std_deviation**2 * toeplitz(np.append([1, rho], np.zeros(n-2)))\n",
    "sm.GLS(y, x_updated, sigma=cov_matrix).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C (25%)\n",
    "1.\tSplit the dataset into two as the training and test sets (test size = 0.5). \n",
    "2.\tRun the Lasso model with alpha=1 and estimate the coefficients using the training set. \n",
    "3.\tThen, calculate the mean absolute percentage error using the test set. \n",
    "4.\tFind an approximate value for alpha that minimizes the mean absolute percentage error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.26972628,  1.68394638,  2.02626245,  2.08756512, -0.91746375,\n",
       "       -0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.01314162,  0.        , -0.        ,  0.        , -0.03617731])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso(alpha=1)\n",
    "lasso.fit(x_train, y_train)\n",
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.04432190198291579)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lasso.predict(x_test)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.001\n",
      "Lowest MAPE: 4.4128318074269805e-05\n"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(-3, 2, 100)  # Try alpha values between 0.001 and 100\n",
    "best_alpha = 1\n",
    "best_mape = float('inf')\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(x_train, y_train)\n",
    "    y_pred = lasso.predict(x_test)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    \n",
    "    if mape < best_mape:\n",
    "        best_mape = mape\n",
    "        best_alpha = alpha\n",
    "\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "print(f\"Lowest MAPE: {best_mape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.9940207931005163\n",
      "AIC: 331.0725918349071\n",
      "BIC: 381.3504638370481\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Step 1: Fit the Lasso model\n",
    "lasso = Lasso(alpha=1)\n",
    "lasso.fit(x_train, y_train)\n",
    "\n",
    "# Step 2: Predict values for the training set\n",
    "y_train_pred = lasso.predict(x_train)\n",
    "\n",
    "# Step 3: Calculate R-squared\n",
    "r_squared = lasso.score(x_train, y_train)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Step 4: Calculate Mean Squared Error (MSE) for AIC and BIC\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "n = x_train.shape[0]  # number of observations\n",
    "k = x_train.shape[1]  # number of features (including the intercept if added)\n",
    "\n",
    "# Step 5: Calculate AIC\n",
    "aic = n * np.log(mse) + 2 * k\n",
    "print(f\"AIC: {aic}\")\n",
    "\n",
    "# Step 6: Calculate BIC\n",
    "bic = n * np.log(mse) + np.log(n) * k\n",
    "print(f\"BIC: {bic}\")\n",
    "\n",
    "# Step 7: Calculate F-statistic (you may need to derive this based on variance analysis)\n",
    "# There isn't a direct formula for F-statistic in Lasso from sklearn,\n",
    "# but it's typically used to compare two models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D (25%)\n",
    "1.\tUse the demand data given in the table and develop an appropriate forecasting model (i.e., the tailored regularization discussed in the class—see your slides for more info) that exploits the available information given in the table as much as possible.\n",
    "2.\tInterpret your results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Month': list(range(1, 26)),\n",
    "    'Demand': [100, 112, 107, 103, 91, 85, 84, 85, 79, 81, 134, 86, 99, 89, 111, 114, 118, 163, 193, 143, 144, 202, 158, 160, 144],\n",
    "    'Advance_demand': [71, 30, 75, 64, 41, 51, 42, 51, 57, 49, 134, 52, 99, 56, 81, 79, 73, 163, 193, 99, 91, 202, 105, 101, 96]\n",
    "}\n",
    "\n",
    "df_d = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Demand</th>\n",
       "      <th>Advance_demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>91</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>85</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>84</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>85</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>79</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>81</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>86</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>89</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>111</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>114</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>118</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>143</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>144</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>158</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>160</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>144</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month  Demand  Advance_demand\n",
       "0       1     100              71\n",
       "1       2     112              30\n",
       "2       3     107              75\n",
       "3       4     103              64\n",
       "4       5      91              41\n",
       "5       6      85              51\n",
       "6       7      84              42\n",
       "7       8      85              51\n",
       "8       9      79              57\n",
       "9      10      81              49\n",
       "10     11     134             134\n",
       "11     12      86              52\n",
       "12     13      99              99\n",
       "13     14      89              56\n",
       "14     15     111              81\n",
       "15     16     114              79\n",
       "16     17     118              73\n",
       "17     18     163             163\n",
       "18     19     193             193\n",
       "19     20     143              99\n",
       "20     21     144              91\n",
       "21     22     202             202\n",
       "22     23     158             105\n",
       "23     24     160             101\n",
       "24     25     144              96"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 16.12293300907556\n",
      "Model Coefficients: [0.69681898]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "# Step 1: 准备数据\n",
    "X = df_d[['Advance_demand']]  # 自变量 (特征)\n",
    "y = df_d['Demand']  # 因变量 (目标)\n",
    "\n",
    "# Step 2: 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 3: 运行 Lasso 模型\n",
    "lasso = Lasso(alpha=1)  # alpha 是正则化强度的参数\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: 预测和评估模型\n",
    "y_pred = lasso.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# 打印模型系数\n",
    "print(f\"Model Coefficients: {lasso.coef_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型公式：\n",
    "\n",
    "$ y = \\beta_0 + \\beta_1 \\cdot X_1 + \\epsilon $\n",
    "\n",
    "具体参数代入：\n",
    "\n",
    "$ y = 0 + 0.6968 \\cdot \\text{Advance demand} + \\epsilon $"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
